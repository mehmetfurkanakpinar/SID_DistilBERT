{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shap\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "# Allocate gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model and tokenizer from the specified checkpoint\n",
    "checkpoint_dir = \"path-to-checkpoint\"\n",
    "model = DistilBertForSequenceClassification.from_pretrained(checkpoint_dir).to(device)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint_dir)\n",
    "model.eval()\n",
    "\n",
    "# Model prediction function\n",
    "def model_predict(input_ids):\n",
    "    input_ids = torch.tensor(input_ids).to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    return probabilities.cpu().numpy()\n",
    "\n",
    "# Load the test dataset\n",
    "file_path = \"/path-to-test_dataset\"\n",
    "test_df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# Choose balanced random samples\n",
    "suicide_df = test_df[test_df['class'] == 'suicide'].sample(20)\n",
    "non_suicide_df = test_df[test_df['class'] == 'non-suicide'].sample(20)\n",
    "balanced_sample_df = pd.concat([suicide_df, non_suicide_df])\n",
    "\n",
    "# Tokenize the samples\n",
    "sampled_texts = balanced_sample_df['text'].tolist()\n",
    "encodings = tokenizer(sampled_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# SHAP Explainer and calculate the values\n",
    "explainer = shap.KernelExplainer(model_predict, encodings['input_ids'].cpu().numpy())\n",
    "shap_values = explainer.shap_values(encodings['input_ids'].cpu().numpy(), nsamples=100)\n",
    "\n",
    "# Visualisation\n",
    "shap.summary_plot(shap_values, feature_names=tokenizer.convert_ids_to_tokens(encodings['input_ids'][0].cpu().numpy()))\n",
    "plt.savefig(\"path-to-save-shap.png\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
